{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.6 - Undervalued, Top-Rated Listings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves to provide insight on undervalued and top-rated listings in the test set.\n",
    "\n",
    "- *Undervalued* listings are defined as the listings for which the price is lower than the predicted value of the model.\n",
    "- *Top-rated* listings are defined as the listings which have the highest positive sentimental score.\n",
    "\n",
    "In the following section, the the most undervalued listings are identified in the test set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Undervalued Listings\n",
    "\n",
    "As a first step, the employed python libraries are imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib as jl\n",
    "import preprocessing as ppc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the listings and the reviews are read. Moreover, the function `test_listing_ids` is defined which is later used to retrieve the listing IDs for all listings in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = pd.read_csv('../../data/listings.csv')\n",
    "reviews1 = pd.read_csv('../../data/reviews1.csv')\n",
    "reviews2 = pd.read_csv('../../data/reviews2.csv')\n",
    "reviews3 = pd.read_csv('../../data/reviews3.csv')\n",
    "reviews4 = pd.read_csv('../../data/reviews4.csv')\n",
    "\n",
    "reviews = pd.concat([reviews1, reviews2, reviews3, reviews4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_listing_ids(listings):\n",
    "    \"\"\"\n",
    "    Retrieve test set listing IDs. This method applies to the input some of the \n",
    "    preprocessing steps which are necessary to correctly identify and retrieve the IDs.\n",
    "\n",
    "    :param listings: Input DataFrame\n",
    "    :return: pandas.Series containing listing IDs of test set.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data_copy = listings.copy()\n",
    "    data_copy.drop([\"neighbourhood_group_cleansed\", \"bathrooms\", \"calendar_updated\"],\n",
    "                   axis=1, inplace=True)\n",
    "    data_copy.drop([\"listing_url\", \"picture_url\", \"host_url\", \"host_thumbnail_url\", \"host_picture_url\"],\n",
    "                   axis=1, inplace=True)\n",
    "    data_copy.drop([\"scrape_id\", \"host_id\"],\n",
    "                   axis=1, inplace=True)\n",
    "    data_copy.drop([\"name\", \"description\", \"neighborhood_overview\", \"host_name\", \"host_about\", \"host_location\",\n",
    "                    \"host_neighbourhood\", \"host_verifications\", \"neighbourhood\", \"license\"],\n",
    "                   axis=1, inplace=True)\n",
    "    data_copy.drop([\"last_scraped\", \"calendar_last_scraped\"],\n",
    "                   axis=1, inplace=True)\n",
    "    \n",
    "    data_copy = data_copy[~data_copy.iloc[:, 1:].duplicated()]\n",
    "    \n",
    "    data_copy = data_copy.dropna(thresh=data_copy.shape[1]-3)\n",
    "    X_train, X_test = train_test_split(data_copy, test_size=0.3, random_state=42)\n",
    "    \n",
    "    return X_test[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having provided the necessary tools for the task in question, we proceed to load the trained model and the fitted scaler. We run the preprocessing pipeline in order to obtain `X_test` and `y_test`. \n",
    "\n",
    "A DataFrame `test_listings` is constructed which contains the retrieved listing IDs for the listings in the test set (`id`), the price value predicted by the model (`prediction`) and the listed price of the accommodation (`price`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and the fitted scaler.\n",
    "model = jl.load('../fastapi/data/regressor.joblib')\n",
    "scaler = jl.load('../fastapi/data/scaler.joblib')\n",
    "\n",
    "# Obtain the test set.\n",
    "X_train, X_test, y_train, y_test = ppc.run_preprocessing_pipeline(listings)\n",
    "\n",
    "# Produce a DataFrame that contains only listing IDs along the the registered and predicted prices.\n",
    "test_listings = pd.DataFrame(data=test_listing_ids(listings),columns=['id']);\n",
    "test_listings['prediction'] = model.predict(X_test)\n",
    "test_listings['price'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, the prediction error is computed and stored as a column in `test_listings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_listings['prediction_error'] = test_listings['prediction'] - test_listings['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10 most undervalued listings are presented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>price</th>\n",
       "      <th>prediction_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28883633</td>\n",
       "      <td>961.227749</td>\n",
       "      <td>473.0</td>\n",
       "      <td>488.227749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33902024</td>\n",
       "      <td>390.944552</td>\n",
       "      <td>71.0</td>\n",
       "      <td>319.944552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>478626</td>\n",
       "      <td>369.053455</td>\n",
       "      <td>120.0</td>\n",
       "      <td>249.053455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29951541</td>\n",
       "      <td>351.303464</td>\n",
       "      <td>110.0</td>\n",
       "      <td>241.303464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18064024</td>\n",
       "      <td>310.603013</td>\n",
       "      <td>83.0</td>\n",
       "      <td>227.603013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4812115</td>\n",
       "      <td>238.635238</td>\n",
       "      <td>48.0</td>\n",
       "      <td>190.635238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17186613</td>\n",
       "      <td>257.238749</td>\n",
       "      <td>70.0</td>\n",
       "      <td>187.238749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14864433</td>\n",
       "      <td>206.750919</td>\n",
       "      <td>20.0</td>\n",
       "      <td>186.750919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20271395</td>\n",
       "      <td>308.439627</td>\n",
       "      <td>175.0</td>\n",
       "      <td>133.439627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>968409</td>\n",
       "      <td>204.171771</td>\n",
       "      <td>73.0</td>\n",
       "      <td>131.171771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prediction  price  prediction_error\n",
       "0  28883633  961.227749  473.0        488.227749\n",
       "1  33902024  390.944552   71.0        319.944552\n",
       "2    478626  369.053455  120.0        249.053455\n",
       "3  29951541  351.303464  110.0        241.303464\n",
       "4  18064024  310.603013   83.0        227.603013\n",
       "5   4812115  238.635238   48.0        190.635238\n",
       "6  17186613  257.238749   70.0        187.238749\n",
       "7  14864433  206.750919   20.0        186.750919\n",
       "8  20271395  308.439627  175.0        133.439627\n",
       "9    968409  204.171771   73.0        131.171771"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_listings.sort_values([\"prediction_error\"], ascending=False, ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Top-Rated Listings\n",
    "In this section, top-rated listings are identified based on sentimental analysis of the two most recent reviews for each listing.\n",
    "\n",
    "For this task, the following libraries are imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "from googletrans import Translator\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we retrieve the 1st and 2nd most recent reviews for each listing. Since it is not possible to directly group `reviews` by `listing_id`, then sort by `date` and obtain the two most recent reviews for each listing using pandas, a different process is followed.\n",
    "\n",
    "This process involves creating two copies of `reviews`, from which only relevant reviews are kept. *Relevant* reviews are the reviews which refer to listings in the test set and which contain adequate information (e.g. more than 10 characters).\n",
    "\n",
    "`reviews_most_recent1` is grouped by `listing_id` and the the first most recent review for all listings is obtained by using `max` as an aggregate function. Then, reviews present in `reviews_most_recent1` are excluded from `reviews_most_recent2`, which can then be used to obtain the second most recent review by following the same steps.\n",
    "\n",
    "DataFrames `reviews_most_recent1` and `reviews_most_recent2` are then combined appropriately into `reviews_most_recent` to obtain the first and second most recent review comments in a single row for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two copies of reviews\n",
    "reviews_most_recent1 = reviews.copy()\n",
    "reviews_most_recent2 = reviews.copy()\n",
    "\n",
    "# Define a mask of relevant reviews, i.e. reviews that refer to the listings in the test set and which contain more than 10 chars.\n",
    "relevant_reviews = reviews[\"listing_id\"].isin(test_listings[\"id\"]) & (reviews[\"comments\"].str.len() > 10)\n",
    "\n",
    "# The 'date' column is processed into a comparable data type so that the 'max' function can be used on it.\n",
    "reviews_most_recent1[\"date\"] = reviews_most_recent1[\"date\"].apply( lambda x : datetime.strptime(x, '%Y-%m-%d') ) \n",
    "reviews_most_recent2[\"date\"] = reviews_most_recent2[\"date\"].apply( lambda x : datetime.strptime(x, '%Y-%m-%d') ) \n",
    "\n",
    "# Obtain most recent review for each listing.\n",
    "reviews_most_recent1 = reviews_most_recent1[ relevant_reviews ].groupby(\"listing_id\", as_index=False).max('date')\n",
    "\n",
    "# Exclude the first most recent reviews for each listing from 'reviews_most_recent2'. Now, the second most recent review can be obtained.\n",
    "reviews_most_recent2 = reviews_most_recent2[ relevant_reviews ]\n",
    "reviews_most_recent2 = reviews_most_recent2[ ~reviews_most_recent2[\"id\"].isin(reviews_most_recent1[\"id\"]) ]\n",
    "reviews_most_recent2 = reviews_most_recent2.groupby(\"listing_id\", as_index=False).max('date')\n",
    "\n",
    "# Using group_by causes non-numeric columns to be dropped from the dataframes. Retrieve the corresponding comments using inner joins.\n",
    "reviews_most_recent1 = reviews_most_recent1.merge(right=reviews, how='inner', left_on='id', right_on='id')[['listing_id_x','id','comments']]\n",
    "reviews_most_recent2 = reviews_most_recent2.merge(right=reviews, how='inner', left_on='id', right_on='id')[['listing_id_x','id','comments']]\n",
    "\n",
    "# \"Combine\" the two most recent reviews and obtain a DataFrame which contains both reviews in a single row for each listing.\n",
    "# This is done by applying a left join on 'reviews_most_recent1'.\n",
    "reviews_most_recent = reviews.copy()\n",
    "reviews_most_recent = reviews_most_recent1.merge(right=reviews_most_recent2, how='left', left_on='listing_id_x', right_on='listing_id_x')\n",
    "reviews_most_recent = reviews_most_recent[[ 'listing_id_x', 'comments_x', 'comments_y' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we check for any second most recent review being missing and we fill them using a dummy string.\n",
    "\n",
    "Then, the most recent reviews are cleaned from any redundand HTML tags and punctuation marks that may cause problem when analysing the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing second most recent review comments using dummy text.\n",
    "reviews_most_recent[\"comments_y\"] = reviews_most_recent[\"comments_y\"].fillna(\"0\")\n",
    "\n",
    "# Process the first and second most recent reviews remove HTML tags and punctuation marks.\n",
    "reviews_most_recent[\"comments_x\"] = reviews_most_recent[\"comments_x\"].apply( lambda x : BeautifulSoup(str(x)).get_text().translate(str.maketrans(\"\",\"\", string.punctuation) ) )\n",
    "reviews_most_recent[\"comments_y\"] = reviews_most_recent[\"comments_y\"].apply( lambda x : BeautifulSoup(str(x)).get_text().translate(str.maketrans(\"\",\"\", string.punctuation) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following snippets, all selected reviews are translated into English (if they are written in a different language) using a Google Translator API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transl = Translator()\n",
    "transl.raise_Exception = True\n",
    "\n",
    "translated_comments_x = []\n",
    "\n",
    "for comment in reviews_most_recent[\"comments_x\"]:\n",
    "    # Translate the review comment and obtain its text\n",
    "    trans = transl.translate(str(comment), dest='en').text\n",
    "    # Store into 'translated_comments_x'\n",
    "    translated_comments_x.append(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transl = Translator()\n",
    "transl.raise_Exception = True\n",
    "\n",
    "translated_comments_y = []\n",
    "for comment in reviews_most_recent[\"comments_y\"]:\n",
    "    # Translate the review comment and obtain its text\n",
    "    trans = transl.translate(str(comment), dest='en').text\n",
    "    # Store into 'translated_comments_x'\n",
    "    translated_comments_y.append(trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the two reviews for each listing are concatenated and stored in `reviews_most_recent`. This allows us to utilize Microsoft Azure's Cognitive Services using less elements for analysis.\n",
    "\n",
    "DataFrame `reviews_most_recent` is then stored as a binary file, rather than a `.csv` file. This is mainly because of encoding errors encountered when parsing the review comments after storing then in `.csv` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_comments = []\n",
    "\n",
    "for comment1, comment2 in zip(translated_comments_x, translated_comments_y):\n",
    "    translated_comments.append(comment1 + \" \" + comment2)\n",
    "    \n",
    "reviews_most_recent[\"concat_comments\"] = translated_comments\n",
    "\n",
    "jl.dump(reviews_most_recent, 'binary/reviews_most_recent.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment analysis for each listing is conducted on a separate `.ipynb` file which is also provided in our work.\n",
    "\n",
    "The confidence scores for positiveness for the concatenated reviews of each listing are loaded. \n",
    "\n",
    "Then, the scores are added as a new column in `reviews_most_recent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveness = jl.load('binary/sentiment.joblib')\n",
    "reviews_most_recent[\"positiveness\"] = positiveness\n",
    "\n",
    "test_listings = test_listings.merge(right=reviews_most_recent, how=\"left\", left_on=\"id\", right_on=\"listing_id_x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_listings = test_listings[[\"id\",\"prediction\",\"price\",\"prediction_error\",\"positiveness\"]]\n",
    "test_listings[\"positiveness\"] = test_listings[\"positiveness\"].fillna( test_listings[\"positiveness\"].mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the 1600 top-rated listings are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>positiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36306345</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39128229</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31249607</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28277565</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38286280</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>27304758</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>26496151</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>25768811</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>46848814</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>43413046</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1590 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  positiveness\n",
       "0     36306345          1.00\n",
       "1     39128229          1.00\n",
       "2     31249607          1.00\n",
       "3     28277565          1.00\n",
       "4     38286280          1.00\n",
       "...        ...           ...\n",
       "1585  27304758          1.00\n",
       "1586  26496151          1.00\n",
       "1587  25768811          1.00\n",
       "1588  46848814          1.00\n",
       "1589  43413046          0.99\n",
       "\n",
       "[1590 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_listings.sort_values(\"positiveness\", ascending=False, ignore_index=True)[[\"id\",\"positiveness\"]].head(1590)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be noticed from the above analysis, 1589 listings have the highest positiveness score of 1.0, thus are considered to be the the top-rated listings. \n",
    "\n",
    "It should be noted that by keeping more recent reviews for each listing we may be able to acquire a more representative picture for the rating of each listing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
