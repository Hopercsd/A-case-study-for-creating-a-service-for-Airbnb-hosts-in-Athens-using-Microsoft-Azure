{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.6 - Utilizing Microsoft Azure's Cognitive Services for Text Analysis\n",
    "\n",
    "This notebook serves to utilize Azure's Cognitive Services in order to apply sentimental analysis on reviews in order to acquire the positiveness confidence scores for each review.\n",
    "\n",
    "First, install Azure's text analytics library for python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-textanalytics==5.1.0 in /home/stavros/anaconda3/lib/python3.7/site-packages (5.1.0)\n",
      "Requirement already satisfied: azure-common~=1.1 in /home/stavros/anaconda3/lib/python3.7/site-packages (from azure-ai-textanalytics==5.1.0) (1.1.27)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/stavros/anaconda3/lib/python3.7/site-packages (from azure-ai-textanalytics==5.1.0) (1.14.0)\n",
      "Requirement already satisfied: msrest>=0.6.21 in /home/stavros/anaconda3/lib/python3.7/site-packages (from azure-ai-textanalytics==5.1.0) (0.6.21)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.14.0 in /home/stavros/anaconda3/lib/python3.7/site-packages (from azure-ai-textanalytics==5.1.0) (1.21.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/stavros/anaconda3/lib/python3.7/site-packages (from msrest>=0.6.21->azure-ai-textanalytics==5.1.0) (2019.11.28)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /home/stavros/anaconda3/lib/python3.7/site-packages (from msrest>=0.6.21->azure-ai-textanalytics==5.1.0) (1.3.0)\n",
      "Requirement already satisfied: requests~=2.16 in /home/stavros/anaconda3/lib/python3.7/site-packages (from msrest>=0.6.21->azure-ai-textanalytics==5.1.0) (2.26.0)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /home/stavros/anaconda3/lib/python3.7/site-packages (from msrest>=0.6.21->azure-ai-textanalytics==5.1.0) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/stavros/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-textanalytics==5.1.0) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/stavros/anaconda3/lib/python3.7/site-packages (from requests~=2.16->msrest>=0.6.21->azure-ai-textanalytics==5.1.0) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/stavros/anaconda3/lib/python3.7/site-packages (from requests~=2.16->msrest>=0.6.21->azure-ai-textanalytics==5.1.0) (1.25.8)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /home/stavros/anaconda3/lib/python3.7/site-packages (from requests~=2.16->msrest>=0.6.21->azure-ai-textanalytics==5.1.0) (2.8)\n"
     ]
    }
   ],
   "source": [
    "! pip install azure-ai-textanalytics==5.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Authentication \n",
    "In this section, access to the Azure Cognitive Services is granted by providing the Key and Endpoint supplied. \n",
    "The Key value is hidden from the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"\"\n",
    "endpoint = \"https://azure-language.cognitiveservices.azure.com/\"\n",
    "\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import joblib as jl\n",
    "import numpy as np\n",
    "\n",
    "def authenticate_client():\n",
    "    \"\"\"\n",
    "    Client authentication method.\n",
    "\n",
    "    :return: the authenticated client instance.\n",
    "    \n",
    "    \"\"\"\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=endpoint, \n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "After being granted access to Azure's API, we can proceed to load the reviews to be analyzed by Azure's Cognitive Services. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_sentiment_analysis(client, documents):\n",
    "    \"\"\"\n",
    "    Method that applies text analysis on the 'documents' argument using the provided 'client'.\n",
    "    More specifically, store and return all positive confidence scores for all elements in\n",
    "    'documents'.\n",
    "    \n",
    "    :param client: the provided client instance to utilize Azure's API.\n",
    "    :param documents: a list of strings to be analyzed.\n",
    "    :return: a list of positive confidence scores.\n",
    "    \n",
    "    \"\"\"\n",
    "    positiveness = []\n",
    "    response = client.analyze_sentiment(documents=documents)\n",
    "    for r in response:\n",
    "        positiveness.append(r.confidence_scores.positive)\n",
    "    \n",
    "    return positiveness\n",
    "\n",
    "# Load the review comments to be analyzed.\n",
    "reviews = jl.load('fastapi/data/reviews_most_recent.joblib')\n",
    "comments = reviews[\"concat_comments\"]\n",
    "\n",
    "# Due to Cognitive Services restriction of maximum 10 elements to be processed each time,\n",
    "# the comments are broken into smaller chunks of data.\n",
    "sentiment = []\n",
    "for i in range(0, len(comments), 10):\n",
    "    com = comments.tolist()[i:i+10]\n",
    "    res = comment_sentiment_analysis(client, com)\n",
    "    sentiment.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, the unravelled positiveness scores are stored as a binary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jl.dump(np.ravel(sentiment),'fastapi/data/sentiment.joblib')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a37465fbdbeb13e348881c420adc194d55817d2123e3276a1b86821649f71833"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
